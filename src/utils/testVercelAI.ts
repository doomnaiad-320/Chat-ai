import { generateText } from 'ai';
import { openai } from '@ai-sdk/openai';

// ç®€å•çš„Vercel AI SDKæµ‹è¯•å‡½æ•°
export const testVercelAIBasic = async (apiKey: string, message: string = 'Hello') => {
  try {
    console.log('ğŸ§ª å¼€å§‹æµ‹è¯•Vercel AI SDK...');
    
    const { text } = await generateText({
      model: openai('gpt-3.5-turbo', {
        apiKey: apiKey,
      }),
      messages: [
        { role: 'user', content: message }
      ],
      maxTokens: 50,
      temperature: 0.7,
    });

    console.log('âœ… Vercel AI SDKæµ‹è¯•æˆåŠŸ!');
    console.log('ğŸ“ AIå›å¤:', text);
    return { success: true, response: text };
  } catch (error) {
    console.error('âŒ Vercel AI SDKæµ‹è¯•å¤±è´¥:', error);
    return { success: false, error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯' };
  }
};

// æµ‹è¯•ä¸åŒçš„é…ç½®
export const testVercelAIWithConfig = async (config: {
  apiKey: string;
  baseURL?: string;
  model?: string;
  message?: string;
}) => {
  try {
    console.log('ğŸ§ª å¼€å§‹æµ‹è¯•Vercel AI SDK (è‡ªå®šä¹‰é…ç½®)...');
    console.log('é…ç½®:', config);
    
    const { text } = await generateText({
      model: openai(config.model || 'gpt-3.5-turbo', {
        apiKey: config.apiKey,
        baseURL: config.baseURL,
      }),
      messages: [
        { role: 'user', content: config.message || 'Hello, this is a test' }
      ],
      maxTokens: 100,
      temperature: 0.7,
    });

    console.log('âœ… Vercel AI SDKæµ‹è¯•æˆåŠŸ!');
    console.log('ğŸ“ AIå›å¤:', text);
    return { success: true, response: text };
  } catch (error) {
    console.error('âŒ Vercel AI SDKæµ‹è¯•å¤±è´¥:', error);
    return { success: false, error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯' };
  }
};

// å°†æµ‹è¯•å‡½æ•°æš´éœ²åˆ°å…¨å±€ï¼Œæ–¹ä¾¿åœ¨æµè§ˆå™¨æ§åˆ¶å°ä¸­è°ƒç”¨
if (typeof window !== 'undefined') {
  (window as any).testVercelAI = testVercelAIBasic;
  (window as any).testVercelAIWithConfig = testVercelAIWithConfig;
}
